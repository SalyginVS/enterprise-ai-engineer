# M0: Experiments Log — Журнал экспериментов

> Здесь фиксируются все попытки: удачные и неудачные.  
> Формат: дата · модель · что пробовал · результат · вывод

---

## EXP-000: Первый вызов через curl (до Python)

**Дата:** 25.02.2026  
**Модель:** qwen3:8b  
**Цель:** убедиться что Ollama API отвечает

```bash
# Команда
curl -s http://127.0.0.1:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{"model": "qwen3:8b", "prompt": "Скажи привет", "stream": false}'
```

**Результат:** Положительный.  
**Вывод:** Ответ получен

---
## EXP-001: Первый Python вызов

**Дата:** 25.02.2026  
**Модель:** qwen3:8b  
**Файл:** src/01_raw_http.py
**Цель:** Python → Ollama API → получить ответ

**EXP-001** — результат: `Ollama is running` в браузере после настройки `OLLAMA_HOST=0.0.0.0`. 
Вывод: по умолчанию Ollama слушает только localhost, для сетевого доступа нужен override.conf. 

---
## EXP-002: Второй Python вызов с библиотекой

**Дата:** 25.02.2026    
**Модель:** qwen3:8b  
**Файл:** src/01_raw_http.py и  src/ 02_ollama_library.py
**Цель:** Python → Ollama API → получить ответ

**EXP-002** — результат: ответ получен. Время: 6.6 сек (первый вызов, холодный старт) и 2.4 сек (через библиотеку, модель уже в VRAM). 
Вывод: первый вызов включает загрузку модели, последующие — только генерацию.

---
## EXP-003: Сравнение моделей на одном промпте

Дата: 25.02.2026
Файл: src/03_token_stats.py

| Модель          | tok/s | Токенов | Общее время |
|-----------------|-------|---------|-------------|
| qwen3:8b        | 130.9 | 273     | 3.9s        |
| deepseek-r1:14b | 82.6  | 268     | 20.2s       |

Ключевой инсайт: у deepseek-r1:14b генерация заняла 3.24с,
но общее время 20.2с — 17 секунд ушло на блок <think>
(внутреннее рассуждение до финального ответа).
Ollama не включает thinking-фазу в eval_duration.

Вывод: qwen3:8b для быстрых итераций, deepseek-r1:14b
только для задач где нужно глубокое рассуждение.

---

## EXP-004: Сравнение моделей на одном промпте

Дата: 25.02.2026
Файл: src/03_token_stats.py

| Модель          | tok/s | Токенов | Общее время |
|-----------------|-------|---------|-------------|
| qwen3:8b        | 130.9 | 273     | 3.9s        |
| deepseek-r1:14b | 82.6  | 268     | 20.2s       |

Ключевой инсайт: у deepseek-r1:14b генерация заняла 3.24с,
но общее время 20.2с — 17 секунд ушло на блок <think>
(внутреннее рассуждение до финального ответа).
Ollama не включает thinking-фазу в eval_duration.

Вывод: qwen3:8b для быстрых итераций, deepseek-r1:14b
только для задач где нужно глубокое рассуждение.

---

## EXP-005: Few-Shot Examples — пограничные случаи

Дата: 25.02.2026
Файл: src/05_few_shot.py

Microsoft 365 → services ✅ (пограничный кейс решён верно)
Lenovo ThinkPad → electronics ⚠️  (ожидали equipment)
Курьерська доставка → services ✅ (украинский работает)

ГРАБЛИ: модель изобрела категорию "electronics" которой нет в списке.
Причина: в few-shot примерах не было примера для категории "equipment".
Модель заполнила пробел своей логикой — нарушила контракт формата.

Урок: few-shot должен покрывать ВСЕ категории.
Решение в M1: Pydantic enum — жёсткая валидация на уровне кода.