# M0: Experiments Log — Журнал экспериментов

> Здесь фиксируются все попытки: удачные и неудачные.  
> Формат: дата · модель · что пробовал · результат · вывод

---

## О модуле M0 и этом журнале

### Контекст и цель модуля

M0 — это недельный boot-camp, точка входа в программу. Исходная позиция: широкий ИТ-опыт, минимальный практический опыт работы с LLM API. Цель на выходе: уверенное понимание того как LLM работает под капотом, и первый рабочий прототип агента-классификатора.

Весь M0 строится вокруг одного бизнес-кейса — классификации инвойсов (счетов-фактур) по категориям расходов. Это не случайный выбор: задача достаточно простая чтобы сосредоточиться на механике LLM, и достаточно реальная чтобы сразу думать про production-ограничения.

### Теоретическая база

**Как работает LLM-вызов.** Модель — это статичный файл весов на диске. Ollama загружает его в VRAM (видеопамять GPU) при первом запросе и держит там пока не вытеснит другая модель или не истечёт таймаут. Каждый запрос — это HTTP POST на порт 11434 с JSON-телом: модель, сообщения, параметры. Ответ возвращается либо потоком (stream: true — токен за токеном), либо целиком (stream: false — ждём полного ответа).

**Токен и скорость генерации.** Токен — это примерно слово или часть слова (в среднем 0.75 слова на токен для английского, чуть меньше для кириллицы). Модель генерирует токены последовательно, один за другим. Скорость измеряется в tok/s (токенов в секунду). На RTX 3090 с qwen3:8b это ~130 tok/s. Важно разделять: время загрузки модели в VRAM (один раз, холодный старт), время обработки промпта (prompt eval), и время генерации ответа (eval). Для reasoning-моделей типа deepseek-r1 добавляется фаза thinking, которую Ollama не включает в eval_duration.

**Три роли сообщений.** Каждый запрос содержит messages — массив объектов с полем role. Роль `system` задаёт контекст и правила поведения модели один раз для всего диалога. Роль `user` — это входящее сообщение от пользователя или агента. Роль `assistant` — предыдущие ответы модели (используется для поддержания контекста диалога). Забытый system prompt — одна из самых частых ошибок: переменная определена, но не передана в messages.

**Temperature (температура).** Параметр от 0.0 до 1.0 управляет случайностью генерации. При temperature=0.0 модель детерминирована — всегда выбирает наиболее вероятный токен. При temperature=1.0 — творческая и разнообразная. Для классификации и structured output используем 0.1: предсказуемость важнее разнообразия.

**Три паттерна промптинга.** В M0 отрабатываются три базовых паттерна которые станут строительными блоками всех последующих агентов. System Prompt + JSON — модель получает роль и формат ответа через system, генерирует структурированный JSON; подходит для стандартных случаев, минимальные токены. Few-Shot (обучение на примерах) — вместо описания правил показываем примеры входа/выхода; модель "понимает" паттерн и применяет его к новым данным; важно покрывать все категории иначе модель изобретает собственные. Chain-of-Thought (цепочка рассуждений) — модель сначала думает пошагово в теге `<thinking>`, потом даёт финальный ответ; точнее на сложных пограничных случаях, но дороже по токенам и времени.

**Проблема калибровки уверенности.** LLM не умеют честно оценивать собственную уверенность. Модель возвращает confidence=0.95 на очевидных кейсах и на пограничных одинаково. Это структурная особенность, не баг конкретной модели. Решение — валидация не через числовой confidence, а через структурные признаки: соответствие enum, наличие признаков неопределённости в тексте reasoning.

### Что делается в M0: карта экспериментов

| EXP | Что проверяем | Ключевой вывод |
|-----|---------------|----------------|
| EXP-000 | Ollama API через curl | Базовая связность стенда |
| EXP-001 | Сетевой доступ с ноутбука | OLLAMA_HOST=0.0.0.0 обязателен |
| EXP-002 | Python HTTP vs библиотека | Холодный старт vs прогретая VRAM |
| EXP-003 | Сравнение моделей, токены | qwen3:8b быстрый, deepseek-r1 думает |
| EXP-004 | System Prompt + JSON | Забытый system = сломанный формат |
| EXP-005 | Few-Shot примеры | Неполное покрытие = галлюцинация категорий |
| EXP-006 | Chain-of-Thought | CoT точнее но дороже, CAPEX требует бизнес-правил |
| EXP-007 | Smart Pipeline | Промпт влияет на результат не меньше данных |

### Связь с последующими модулями

Все проблемы обнаруженные в M0 получат системное решение в M1: Pydantic-валидация закроет проблему невалидных категорий (EXP-005), структурный escalation заменит ненадёжный confidence (EXP-007), retry-логика обработает нестабильный JSON (EXP-004). Smart Pipeline из EXP-007 станет архитектурным скелетом Invoice Classifier Agent в M1.

---

## EXP-000: Первый вызов через curl (до Python)

**Дата:** 25.02.2026  
**Модель:** qwen3:8b  
**Цель:** убедиться что Ollama API отвечает

```bash
# Команда
curl -s http://127.0.0.1:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{"model": "qwen3:8b", "prompt": "Скажи привет", "stream": false}'
```

**Результат:** Положительный.  
**Вывод:** Ответ получен

---
## EXP-001: Первый Python вызов

**Дата:** 25.02.2026  
**Модель:** qwen3:8b  
**Файл:** src/01_raw_http.py
**Цель:** Python → Ollama API → получить ответ

**EXP-001** — результат: `Ollama is running` в браузере после настройки `OLLAMA_HOST=0.0.0.0`. 
Вывод: по умолчанию Ollama слушает только localhost, для сетевого доступа нужен override.conf. 

---
## EXP-002: Второй Python вызов с библиотекой

**Дата:** 25.02.2026    
**Модель:** qwen3:8b  
**Файл:** src/01_raw_http.py и  src/ 02_ollama_library.py
**Цель:** Python → Ollama API → получить ответ

**EXP-002** — результат: ответ получен. Время: 6.6 сек (первый вызов, холодный старт) и 2.4 сек (через библиотеку, модель уже в VRAM). 
Вывод: первый вызов включает загрузку модели, последующие — только генерацию.

---
## EXP-003: Сравнение моделей на одном промпте

Дата: 25.02.2026
Файл: src/03_token_stats.py

| Модель          | tok/s | Токенов | Общее время |
|-----------------|-------|---------|-------------|
| qwen3:8b        | 130.9 | 273     | 3.9s        |
| deepseek-r1:14b | 82.6  | 268     | 20.2s       |

Ключевой инсайт: у deepseek-r1:14b генерация заняла 3.24с,
но общее время 20.2с — 17 секунд ушло на блок <think>
(внутреннее рассуждение до финального ответа).
Ollama не включает thinking-фазу в eval_duration.

Вывод: qwen3:8b для быстрых итераций, deepseek-r1:14b
только для задач где нужно глубокое рассуждение.

---

## EXP-004: Сравнение моделей на одном промпте

Дата: 25.02.2026
Файл: src/04_system_prompt.py

Результат: все 3 инвойса классифицированы верно (office_supplies, services, utilities) Многоязычность: украинский инвойс обработан корректно 

Грабли: забыл передать SYSTEM_PROMPT в messages — модель отвечала свободным текстом вместо JSON. JSON parser вернул пустую строку. 

Урок: system prompt определить мало — нужно явно передать в messages. Наблюдение: confidence всегда 0.95 — LLM плохо калибруют уверенность. 

Решение в M1: валидация через Pydantic + пороговые значения.

---

## EXP-005: Few-Shot Examples — пограничные случаи

Дата: 25.02.2026
Файл: src/05_few_shot.py

Microsoft 365 → services ✅ (пограничный кейс решён верно)
Lenovo ThinkPad → electronics ⚠️  (ожидали equipment)
Курьерська доставка → services ✅ (украинский работает)

ГРАБЛИ: модель изобрела категорию "electronics" которой нет в списке.
Причина: в few-shot примерах не было примера для категории "equipment".
Модель заполнила пробел своей логикой — нарушила контракт формата.

Урок: few-shot должен покрывать ВСЕ категории.

Решение в M1: Pydantic enum — жёсткая валидация на уровне кода.

---

## EXP-006: Chain-of-Thought — сложные пограничные случаи

Дата: 25.02.2026
Файл: src/06_chain_of_thought.py

Кейс 1: Dell PowerEdge + монтаж + поддержка → services
  Ожидалось: equipment (CAPEX логика)
  Модель сосредоточилась на глаголах (налаштування, підтримка)
  и перевесила в сторону услуг. Логически связно, но спорно.
  Вывод: пограничные CAPEX-кейсы нужно решать бизнес-правилами,
  а не полагаться только на LLM.

Кейс 2: Herman Miller chairs x20 → equipment ✅
  Верно разграничил office_supplies (канцелярия) vs equipment (мебель).
  Верно проигнорировал доставку как не меняющую категорию.

Сравнение паттернов по токенам и скорости:
  System Prompt + JSON : ~30 токенов,  ~3-4s  — стандартные кейсы
  Few-Shot             : ~100 токенов, ~5-8s  — нужен точный формат
  Chain-of-Thought     : ~200+ токенов, ~10s  — сложные/пограничные

Вывод: в production комбинировать — быстрая классификация сначала,
при низком confidence escalation на CoT.

---

## EXP-007: Smart Pipeline — автовыбор стратегии

Дата: 25.02.2026
Файл: src/07_smart_pipeline.py

Результат: 4/4 валидных, 0 escalations, 19.2s, 2659 токенов

Наблюдение 1: Dell PowerEdge → equipment (fast), но ранее в EXP-006
  тот же инвойс через CoT дал services. Разные промпты = разные ответы.
  Вывод: промпт влияет на результат не меньше чем данные.
  Решение в M6: eval pipeline для сравнения версий промптов.

Наблюдение 2: escalation не сработал ни разу — модель всегда
  возвращает confidence 0.90-0.95, никогда ниже порога 0.85.
  
  Причина: LLM плохо калибруют уверенность (проблема из EXP-004).
  
  Решение в M1: escalation через структурные признаки
  (невалидный enum, слова "unclear/ambiguous" в reasoning).

---

## EXP-008: Первый Tool Call через Ollama

**Дата:** 2026-02-26
**Модель:** qwen3:14b
**Скрипт:** src/08_first_tool.py

**Цель:** Освоить механизм tool calling — базовый паттерн любого агента.

**Ключевые наблюдения:**
- Полный цикл tool calling работает: вопрос → tool request → выполнение → результат → финальный ответ
- Когда модель решает вызвать инструмент: content='' и tool_calls=[...] — это нормальное поведение протокола
- Каждый tool call получает уникальный id ('call_ofrfxano' и т.д.) — важно для будущего параллельного вызова нескольких инструментов
- Один tool use = два HTTP-запроса к модели: первый для принятия решения, второй для формулировки финального ответа
- Edge case отработан корректно: несуществующий INV-2024-999 вернул {"status": "Не найден"}, модель корректно транслировала это пользователю без галлюцинаций
- Выбор qwen3:14b вместо 8b оправдан: модель ни разу не попыталась ответить из собственных знаний, всегда обращалась к инструменту

**Архитектурный инсайт:**
Модель не выполняет инструменты — она только принимает решение о вызове и формулирует запрос.
Весь execution остаётся на стороне Python-кода. Это критически важно для безопасности:
именно здесь в продакшне будут access control, валидация аргументов и аудит-лог.

**Результат:** PASSED — все 3 тест-кейса, включая not-found сценарий

---

## EXP-009: Два инструмента + Agent Loop

**Дата:** 2026-02-26
**Модель:** qwen3:14b
**Скрипт:** src/09_agent_loop.py

**Цель:** Освоить agent loop — цикл, который превращает скрипт в агента.

**Запуск 1:**
- Кейс 1: 2 итерации, один инструмент. Корректно.
- Кейс 2: 3 итерации, последовательная цепочка — модель взяла сумму
  из результата get_invoice_status и передала в convert_currency. Правильно.
  Баг: финальный ответ пустой (content='').
- Кейс 3: 2 итерации, прямой вызов convert_currency. Корректно.

**Запуск 2:**
- Кейс 1: идентично запуску 1. Стабильно.
- Кейс 2: модель вызвала ОБА инструмента параллельно в итерации 1.
  При этом ГАЛЛЮЦИНИРОВАЛА аргументы второго вызова: передала
  amount=10000, from_currency=RUB вместо amount=32100, from_currency=UAH.
  Источник этих значений неизвестен — модель их придумала, не дождавшись
  результата первого инструмента. Финальный ответ сообщил об "отсутствии
  курса UAH→USD", хотя курс в коде есть — ложная причина отказа.
- Кейс 3: идентично запуску 1. Стабильно.

**Ключевой инсайт — Недетерминизм LLM:**
Одинаковый промпт при повторных запусках может давать разную стратегию
вызова инструментов. Модель недетерминирована по природе.
Последствие для продакшна: нельзя полагаться на "модель всегда поступит
правильно". Аргументы инструментов нужно валидировать ДО их выполнения.
Особенно критично для деструктивных операций (запись в БД, отправка email,
финансовые транзакции). Фиксируется как требование к M1.

**Обнаруженные проблемы для M1:**
1. Пустой финальный ответ (content='') — нужен fail-safe fallback
2. Галлюцинация аргументов инструмента — нужна schema validation перед execute
3. Параллельный вызов инструментов без зависимостей — нужен контроль порядка
   когда второй вызов зависит от результата первого

**Результат:** PASSED с критическими наблюдениями для M1.

---

## EXP-010: Валидация аргументов + System Prompt + Fallback

**Дата:** 2026-02-26
**Модель:** qwen3:14b
**Скрипт:** src/10_validated_agent.py

**Цель:** Закрыть баги из EXP-009 — галлюцинация аргументов,
пустой финальный ответ — перед переходом к CustomerSupportAgent.

**Результаты по кейсам:**

Кейс 1 (цепочка get_invoice → convert):
- Оба запуска: последовательные вызовы с корректными аргументами.
- System prompt устранил галлюцинацию из EXP-009. FIXED.
- Запуск 2: пустой content на итерации 3 → fallback сработал,
  итерация 4 вернула полный ответ. FIXED.

Кейс 2 (некорректный номер счёта 12345):
- Запуск 1: валидатор Pydantic поймал '12345', вернул ошибку модели,
  модель корректно попросила правильный формат. Ожидаемо.
- Запуск 2: модель вообще не вызвала инструмент — самостоятельно
  распознала некорректный формат из system prompt и ответила без tool call.
  Оба исхода приемлемы для пользователя.

Кейс 3 (прямая конвертация без счёта):
- Оба запуска: СЛОМАН. Модель отказывается конвертировать без invoice_id.
- Причина: overcorrection в system prompt. Правило "используй только
  реальные значения из get_invoice_status" интерпретируется моделью
  как "любая конвертация требует счёта".
- Решение очевидно: смягчить формулировку правила в system prompt.
- Решение не применяем — это учебный артефакт, фиксируем как наблюдение.

**Ключевые инсайты:**

1. System prompt эффективен против галлюцинации аргументов —
   главная цель достигнута.

2. Fallback на пустой ответ работает — второй запрос с явной
   просьбой сформулировать ответ решает проблему.

3. Pydantic-валидация аргументов до выполнения инструмента —
   обязательный паттерн для продакшна. Перехватывает некорректные
   данные от модели до того, как они попадут в реальную систему.

4. Prompt engineering trade-off: ужесточение одного правила
   может сломать другой сценарий. Нужно тестировать все кейсы
   после каждого изменения system prompt.

5. Недетерминизм управляем, но не устраним: одинаковый вопрос
   в кейсе 2 дал разные пути (tool call vs прямой ответ) —
   оба корректны. В продакшне важен результат, а не путь.

**Что берём в M1:**
- Pydantic-валидация аргументов инструментов — обязательно
- Fallback на пустой ответ — обязательно
- System prompt для управления поведением — обязательно
- Тест-матрица после каждого изменения system prompt — практика

**Результат:** PASSED — основные цели достигнуты,
trade-off задокументирован.

---

## EXP-011: CustomerSupportAgent — Задание 0.4

**Дата:** 2026-02-26
**Модель:** qwen3:14b
**Скрипт:** src/11_customer_support_agent.py

**Цель:** Первый полноценный агент — инкапсулированная логика,
три инструмента, валидация, телеметрия, все паттерны из EXP-008..010.

**Статистика (оба запуска идентичны):**
- total_requests: 7
- tool_calls: 7
- validation_errors: 0
- fallbacks_used: 1
- total_iterations: 15
- avg_iterations_per_request: 2.1

**Результаты по кейсам:**

FAQ (возврат, доставка): корректно, search_faq вызван с правильной темой.
Заказ ORD-002 (в пути): статус + трекинг + детали. Отлично.
Заказ ORD-003 (обрабатывается): статус без трекинга — агент сам
  отметил отсутствие трекинга и предложил подождать. Не галлюцинировал.
Заказ ORD-999 (не существует): корректный not-found ответ оба запуска.
Жалоба: вызвано два инструмента — classify_request + search_faq.
  Классификация верная (complaint), но логика после — поиск в FAQ
  вместо эскалации оператору. Это ограничение отсутствия conditional
  routing. Паттерн для M3.
Программа лояльности: агент ответил без tool call — правильно
  признал границы своих возможностей.

**Архитектурные наблюдения:**

1. Инкапсуляция работает: всё внутри класса, публичный интерфейс
   — один метод handle(). Правильная граница ответственности.

2. Телеметрия как первый класс: stats-словарь — прообраз
   Prometheus-метрик из M1/M2. avg_iterations_per_request = 2.1
   становится базовой метрикой для сравнения в будущем.

3. Стабильность статистики: два запуска — идентичные цифры.
   Агент воспроизводим. Это важнее красоты отдельных ответов.

4. Conditional routing отсутствует: жалоба должна эскалироваться
   оператору, а не уходить в search_faq. Паттерн для M3.

5. fallbacks_used: 1 на 14 запросов (~7%) — fallback необходим,
   подтверждено практикой.

**Результат:** PASSED — задание 0.4 выполнено полностью.
M0 завершён.